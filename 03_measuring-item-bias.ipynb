{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfd46bc-c39e-496e-ad19-9b131e3dda59",
   "metadata": {},
   "source": [
    "## Job Crafting: Measuring Item Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47bd35-1760-4811-8d19-e966bf9fe34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.spatial.distance import cosine as cosdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b5de9-a51f-40f2-bd30-19c03511601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS = 'data/'\n",
    "BIAS = 'bias/'\n",
    "MODE = 'normal'  # change mode to either 'normal' or 'masked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1ab08-5062-4ea3-8a4c-e683f4b7c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-encoded vignette embeddings\n",
    "vignette_embeddings = np.load(EMBEDDINGS + 'vignette_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f2dc47-b83f-406c-afaa-9c38d68497c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-encoded strategy embeddings\n",
    "if MODE == 'normal':\n",
    "    strategy_embeddings = np.load(EMBEDDINGS + 'strategy_embeddings.npy')\n",
    "elif MODE == 'masked':\n",
    "    strategy_embeddings = np.load(EMBEDDINGS + 'strategy_embeddings_masked.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca1b53-9764-4348-8cc9-c1e19f629a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies_per_item = [0, 621, 612, 611, 607]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd434f65-35e7-499f-bfb8-fb69224b9eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WEAT_one_vs_all(item_no=1, random_seed=15):\n",
    "    \"\"\"calculates the WEAT statistic for bias dimension item_no-all_other_items:\n",
    "       Are answers to item_no closer to vignette of item_no in the embedding space\n",
    "       compared to the vignettes of all other items (averaged)?\"\"\"    \n",
    "    start = np.sum(strategies_per_item[:item_no])\n",
    "    stop = start + strategies_per_item[item_no]\n",
    "    other_items = np.delete(strategy_embeddings, range(start, stop), axis=0)\n",
    "    \n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    random_idx = rng.randint(strategy_embeddings.shape[0]-strategies_per_item[item_no],\n",
    "                             size=strategies_per_item[item_no])\n",
    "    \n",
    "    X = strategy_embeddings[start:stop]\n",
    "    Y = other_items[random_idx]\n",
    "\n",
    "    A = vignette_embeddings[item_no - 1]\n",
    "    B = np.delete(vignette_embeddings, (item_no - 1), axis=0)\n",
    "    \n",
    "    s_WAB = []\n",
    "    \n",
    "    s_XAB = 0\n",
    "    for sentence in X:\n",
    "        inner_item_dist = cosdist(sentence, A)\n",
    "        cross_item_dist = np.mean([cosdist(sentence, B[x]) for x in range(len(B))])\n",
    "        s_wAB = inner_item_dist - cross_item_dist\n",
    "        s_WAB.append(s_wAB)\n",
    "        s_XAB += s_wAB\n",
    "    mean_s_XAB = s_XAB / len(X)\n",
    "\n",
    "    s_YAB = 0\n",
    "    for sentence in Y:\n",
    "        cross_item_dist = cosdist(sentence, A)\n",
    "        inner_item_dist = np.mean([cosdist(sentence, B[x]) for x in range(len(B))])\n",
    "        s_wAB = cross_item_dist - inner_item_dist\n",
    "        s_WAB.append(s_wAB)\n",
    "        s_YAB += s_wAB\n",
    "    mean_s_YAB = s_YAB / len(Y)\n",
    "\n",
    "    s_XYAB = s_XAB - s_YAB\n",
    "    \n",
    "    effect_size = (mean_s_XAB - mean_s_YAB) / np.std(s_WAB)\n",
    "\n",
    "    return s_XYAB, effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8340b-8c4f-4df5-aeb4-c75de1ee09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate WEAT statistics for all items: includes (bootstrapped bias statistic, bootstrapped effect size)\n",
    "# save to dictionary/json\n",
    "\n",
    "# bias_results = {}\n",
    "\n",
    "# for item in range(1, 5):\n",
    "      # compute statistic for 1000 times with different seeds to produce confidence interval\n",
    "      # because of random drawing of 'other item's answers'-set\n",
    "#     print(f'Bootstrapping for item {item}...')\n",
    "#     bias_boot = []\n",
    "#     es_boot = []\n",
    "#     for seed in tqdm(np.arange(1000)):\n",
    "#         WEAT = WEAT_one_vs_all(item_no=item, random_seed=seed)\n",
    "#         bias_boot.append(WEAT[0])\n",
    "#         es_boot.append(WEAT[1])\n",
    "    \n",
    "#     bias_results[item] = (bias_boot, es_boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfab46-f37d-46f7-8e3c-ee97ac34c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save bias results to file\n",
    "# with open(BIAS + f'bias_boot_{MODE}.json', 'w') as f:\n",
    "    # f.write(json.dumps(bias_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d56871-3ac3-4929-92f0-1f04d9a9797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload pre-computed bias results\n",
    "with open(BIAS + f'bias_boot_{MODE}.json', 'r') as f:\n",
    "    bias_results = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc4990-b1ab-47dd-ba74-89ab4436a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display bias results in table\n",
    "df_one_vs_all = pd.DataFrame(columns=['statistic (mean)', 'CI (95%)'], index= range(1, 5))\n",
    "\n",
    "for item in range(1, 5):\n",
    "    boot = bias_results[str(item)][0]  # list of bootstrapped statistics\n",
    "    boot.sort()\n",
    "    \n",
    "    df_one_vs_all.loc[item]['statistic (mean)'] = f'{np.mean(boot):.2f}'  # mean of bootstrapped values\n",
    "    df_one_vs_all.loc[item]['CI (95%)'] = f'[{boot[int(len(boot)*0.025-1)]:.2f}; {boot[int(len(boot)*0.975-1)]:.2f}]'  # 0.025th percentile & 0.975th percentile through 25th & 750th value in sorted statistics\n",
    "\n",
    "df_one_vs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4703a003-f981-410b-99cd-d6fc7c3d17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_vs_all = pd.DataFrame(columns=['effect size (mean)', 'CI (95%)'], index= range(1, 5))\n",
    "\n",
    "for item in range(1, 5):\n",
    "    boot = bias_results[str(item)][1]  # list of bootstrapped effect sizes\n",
    "    boot.sort()\n",
    "    \n",
    "    df_one_vs_all.loc[item]['effect size (mean)'] = f'{np.mean(boot):.2f}'  # mean of bootstrapped values\n",
    "    df_one_vs_all.loc[item]['CI (95%)'] = f'[{boot[int(len(boot)*0.025-1)]:.2f}; {boot[int(len(boot)*0.975-1)]:.2f}]'  # 0.025th percentile & 0.975th percentile through 25th & 750th value in sorted effect sizes\n",
    "\n",
    "df_one_vs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe121b-eed9-4bb9-947e-f78a1b64b5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
